# -*- coding: utf-8 -*-
"""Regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSTaLRah3QTlIoobRL6ldZ-ltTcmZwNx
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

!pip install torch-geometric

import torch
from torch_geometric.nn import GCNConv

class Regressor(torch.nn.Module):
    def __init__(self, max_feat_num, depth, nhid, dropout):
        super().__init__()

        self.linears = torch.nn.ModuleList([torch.nn.Linear(max_feat_num, nhid)])
        for _ in range(depth - 1):
            self.linears.append(torch.nn.Linear(nhid, nhid))

        self.convs = torch.nn.ModuleList(
            [GCNConv(nhid, nhid) for _ in range(depth)]
        )

        dim = max_feat_num + depth * nhid
        dim_out = nhid

        self.sigmoid_linear = torch.nn.Sequential(
            torch.nn.Linear(dim, dim_out), torch.nn.Sigmoid()
        )
        self.tanh_linear = torch.nn.Sequential(
            torch.nn.Linear(dim, dim_out), torch.nn.Tanh()
        )

        self.final_linear = torch.nn.Sequential(
            torch.nn.Linear(dim_out, nhid),
            torch.nn.ReLU(),
            torch.nn.Dropout(p=dropout),
            torch.nn.Linear(nhid, 2),
        )

    def forward(self, x, edge_index, edge_attr=None):
        xs = [x]
        out = x
        for lin, conv in zip(self.linears, self.convs):
            out = lin(out)
            if edge_attr is not None:
                out = conv(out, edge_index)
            else:
                out = conv(out, edge_index)
            out = torch.tanh(out)
            xs.append(out)
        out = torch.cat(xs, dim=-1)

        sigmoid_out = self.sigmoid_linear(out)
        tanh_out = self.tanh_linear(out)
        out = torch.mul(sigmoid_out, tanh_out).sum(dim=1)
        embeds = torch.tanh(out)
        preds = self.final_linear(embeds)
        preds[:, 0] = torch.sigmoid(preds[:, 0])

        return preds, embeds

class RegressorEnsemble(torch.nn.Module):
    def __init__(self,max_feat_num, depth, nhid, dropout, ensemble_size):
        super().__init__()
        self.regressors = torch.nn.ModuleList(
            [
                Regressor(max_feat_num, depth, nhid, dropout)
                for _ in range(ensemble_size)
            ]
        )

    def forward(self,x,edge_index,edge_attr=None):

        preds = []
        embeds = []
        for regressor in self.regressors:
            pred, embed = regressor(x, edge_index, edge_attr=None)
            preds.append(pred)
            embeds.append(embed)

        return preds, embeds

import torch
from torch_geometric.data import Data

# Initialize the Regressor
max_feat_num = 16  # Number of input features per node
depth = 3          # Number of GCN layers
nhid = 10         # Hidden layer size
dropout = 0.5      # Dropout rate

model = Regressor(max_feat_num=max_feat_num, depth=depth, nhid=nhid, dropout=dropout)

# Dummy Graph Data
num_nodes = 10
edge_index = torch.tensor([
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  # Source nodes
    [1, 2, 3, 4, 5, 6, 7, 8, 9, 0],  # Target nodes
], dtype=torch.long)  # Shape: [2, num_edges]

x = torch.rand((num_nodes, max_feat_num))  # Node features (randomly generated)
edge_attr = torch.rand((edge_index.size(1), 1))  # Edge attributes (optional)

# Forward Pass
preds, embeds = model(x, edge_index)

# Output Results
print("Predictions (preds):", preds.shape)
print("Embeddings (embeds):", embeds.shape)